
kafka {
  input.topic = "telemetry.ingest"
  output.success.topic = "flink.telemetry.raw"
  output.duplicate.topic = "flink.telemetry.duplicate"
  output.failed.topic = "flink.telemetry.failed"
  event.max.size = "1048576" # Max is only 1MB
  groupId = "sunbirddev.telemetry.extractor.group"
  broker-servers = "localhost:9092"
  zookeeper = "localhost:2181"
}

task {
  parallelism = 1
  checkpointing.interval = 60000
  dedup {
    parallelism = 1
  }
  extraction {
    parallelism = 1
  }
}

telemetry.schema.path="schemas/telemetry/3.0"
router.secondary.routes.eid = ["LOG", "ERROR"]
default.channel="org.sunbird"
dedup.producer.included.ids = ["prod.diksha.portal", "prod.sunbird.desktop"]

task.validation.parallelism = 2
task.router.parallelism = 1
task.flattener.parallelism = 2

redis {
  # dev-environment
  host = localhost
  port = 6379
  connection {
    max = 2
    idle.min = 1
    idle.max = 2
    minEvictableIdleTimeSeconds = 120
    timeBetweenEvictionRunsSeconds = 300
  }
  database {
    duplicationstore.id = 12
    key.expiry.seconds = 3600
  }
}