kafka {
  input.topic = "k8s.telemetry.ingest.flink"
  output.success.topic = "k8s.telemetry.raw.flink"
  output.duplicate.topic = "k8s.telemetry.duplicate.flink"
  output.failed.topic = "k8s.telemetry.failed.flink"
  output.metrics.topic = "k8s.telemetry.metrics.flink"
  broker-servers = "127.0.0.1:9092"
  zookeeper = "127.0.0.1:2181"
  event.max.size = "102400" # Max is 100 Kb
  groupId = "telemetry-extractor-group"
}

task {
  parallelism = 1
  checkpointing.interval = 60000
  restart-strategy.attempts = 1 # retry once
  restart-strategy.delay = 1000 # in milli-seconds
  metrics.window.size = 5000 # 5 seconds for test cases
  dedup {
  parallelism = 1
  validation.required = true
  }
  extraction {
    parallelism = 1
  }
}
redis {
  host = 127.0.0.1
  port = 6340
  connection {
    max = 2
    idle.min = 1
    idle.max = 2
    minEvictableIdleTimeSeconds = 120
    timeBetweenEvictionRunsSeconds = 300
  }
  database {
    duplicationstore.id = 1
    key.expiry.seconds = 3600
  }
}